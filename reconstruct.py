import argparse
import os
import sys

import numpy as np
import chainer
from chainer import training
from chainer.training import extension
from chainer.training import extensions
from chainer.datasets import TransformDataset
from chainercv.transforms import random_rotate
from chainercv.transforms.image.resize import resize

sys.path.append(os.path.dirname(__file__))

from common.dataset import Cifar10Dataset
from common.dataset import ImagenetDataset
from common.dataset import CelebA
from common.evaluation import sample_generate, sample_generate_light, calc_inception, calc_FID
from common.record import record_setting
import common.net


def make_optimizer(model, alpha, beta1, beta2):
    optimizer = chainer.optimizers.Adam(alpha=alpha, beta1=beta1, beta2=beta2)
    optimizer.setup(model)
    return optimizer


parser = argparse.ArgumentParser(description='Train script')
parser.add_argument('--algorithm', '-a', type=str, default="dcgan", help='GAN algorithm')
parser.add_argument('--architecture', type=str, default="dcgan", help='Network architecture')
parser.add_argument('--batchsize', type=int, default=64)
parser.add_argument('--max_iter', type=int, default=100000)
parser.add_argument('--gpu', '-g', type=int, default=0, help='GPU ID (negative value indicates CPU)')
parser.add_argument('--out', '-o', default='result', help='Directory to output the result')
parser.add_argument('--snapshot_interval', type=int, default=10000, help='Interval of snapshot')
parser.add_argument('--evaluation_interval', type=int, default=10000, help='Interval of evaluation')
parser.add_argument('--display_interval', type=int, default=100, help='Interval of displaying log to console')
parser.add_argument('--n_dis', type=int, default=5, help='number of discriminator update per generator update')
parser.add_argument('--gamma', type=float, default=0.5, help='hyperparameter gamma')
parser.add_argument('--lam', type=float, default=10, help='gradient penalty')
parser.add_argument('--adam_alpha', type=float, default=0.0001, help='alpha in Adam optimizer')
parser.add_argument('--adam_beta1', type=float, default=0.5, help='beta1 in Adam optimizer')
parser.add_argument('--adam_beta2', type=float, default=0.9, help='beta2 in Adam optimizer')
parser.add_argument('--output_dim', type=int, default=256, help='output dimension of the discriminator (for cramer GAN)')

args = parser.parse_args()
record_setting(args.out)
report_keys = ["loss_enc", "loss_dis", "loss_gen", "inception_mean", "inception_std", "FID"]

# Set up dataset
# train_dataset = Cifar10Dataset()
# train_dataset = CelebA()
dataset = np.load('./hrp2.npz')['arr_0']


def transform(in_data):
    img = in_data
    img = img.astype(np.float32).transpose((2, 0, 1))
    img /= 255.0
    img = resize(img, (128, 128))
    return img


train_dataset = TransformDataset(dataset, transform)
train_iter = chainer.iterators.SerialIterator(train_dataset, args.batchsize)

# Setup algorithm specific networks and updaters
models = []
opts = {}
updater_args = {
    "iterator": {'main': train_iter},
    "device": args.gpu
}


from vaegan.updater import Updater
size = 128
bottom_width = (size // 8)
encoder = common.net.VAEEncoder(size=size)
generator = common.net.DCGANGenerator(n_hidden=100, bottom_width=bottom_width,
                                      ch=256, z_distribution="normal")
discriminator = common.net.DCGANDiscriminator(ch=256, bottom_width=bottom_width,
                                              output_dim=2)
models = [encoder, generator, discriminator]


if args.gpu >= 0:
    chainer.cuda.get_device_from_id(args.gpu).use()
    print("use gpu {}".format(args.gpu))
    for m in models:
        m.to_gpu()


chainer.serializers.load_npz('./result/VAEEncoder_10000.npz', encoder)
chainer.serializers.load_npz('./result/DCGANGenerator_10000.npz', generator)
chainer.serializers.load_npz('./result/DCGANDiscriminator_10000.npz',
                             discriminator)


def sample_generate2(gen, dst, rows=10, cols=10, seed=0):
    """Visualization of rows*cols images randomly generated by the generator."""
    from PIL import Image

    np.random.seed(seed)
    n_images = rows * cols
    xp = gen.xp
    z = chainer.Variable(xp.asarray(gen.make_hidden(n_images)))
    with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
        x = gen(z)
    x = chainer.cuda.to_cpu(x.data)
    np.random.seed()

    x = np.asarray(np.clip(x * 255.0, 0.0, 255.0), dtype=np.uint8)
    _, _, h, w = x.shape
    x = x.reshape((rows, cols, 3, h, w))
    x = x.transpose(0, 3, 1, 4, 2)
    x = x.reshape((rows * h, cols * w, 3))

    preview_dir = '{}/preview'.format(dst)
    preview_path = preview_dir + '/image1.png'
    if not os.path.exists(preview_dir):
        os.makedirs(preview_dir)
    Image.fromarray(x).save(preview_path)


def sample_generate2(gen, dst, rows=10, cols=10, seed=0):
    """Visualization of rows*cols images randomly generated by the generator."""
    from PIL import Image

    np.random.seed(seed)
    n_images = rows * cols
    xp = gen.xp
    z = chainer.Variable(xp.asarray(gen.make_hidden(n_images)))
    with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
        x = gen(z)
    x = chainer.cuda.to_cpu(x.data)
    np.random.seed()

    x = np.asarray(np.clip(x * 255.0, 0.0, 255.0), dtype=np.uint8)
    _, _, h, w = x.shape
    x = x.reshape((rows, cols, 3, h, w))
    x = x.transpose(0, 3, 1, 4, 2)
    x = x.reshape((rows * h, cols * w, 3))

    preview_dir = '{}/preview'.format(dst)
    preview_path = preview_dir + '/image1.png'
    if not os.path.exists(preview_dir):
        os.makedirs(preview_dir)
    Image.fromarray(x).save(preview_path)


def reconstruct(encoder, generator):
    import cv2
    for i in range(10):
        n = np.random.randint(len(train_dataset))
        img = train_dataset[n]
        cv2.imwrite('/tmp/original_{}.png'.format(i),
                    np.asarray(255 * img, dtype=np.uint8).transpose((1, 2, 0)))
        z_rec, mu_z, ln_var_z = encoder(chainer.cuda.to_gpu(train_dataset[n][None, ]))
        x_rec = generator(z_rec)
        rec_img = np.asarray(chainer.cuda.to_cpu((x_rec * 255.0).data),
                             dtype=np.uint8)
        cv2.imwrite('/tmp/rec_{}.png'.format(i),
                    rec_img.reshape(3, 128, 128).transpose((1, 2, 0)))


# sample_generate2(generator, args.out)
reconstruct(encoder, generator)
